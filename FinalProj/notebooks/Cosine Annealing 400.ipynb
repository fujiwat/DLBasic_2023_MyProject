{"cells":[{"cell_type":"markdown","metadata":{"id":"MUWcdth_khfN"},"source":["# DLBasics2023 最終課題\n","実行結果付き。\n","参考データ収集用.（Cosine Annealing 400回）\n","### 作者： tfujiwara\n","### 日付： 2023-Aug-02"]},{"cell_type":"markdown","metadata":{"id":"gAjuP7I4lWyn"},"source":["## 課題\n","第11回「変分オートエンコーダ（VAE）を用いてFasionMNISTの画像を生成してみましょう」<br>\n","を発展させ、学習率探索プログラムを開発する\n","\n","### 目標\n","\n","課題の目標値は「NLL（負の対数尤度） 235」であったが、これにこだわらず、\n","自動探索により、良い検証結果の出る学習率が得られることとする。\n","以下の、オリジナル課題ルールは、あえて変更せず、**学習率とエポック数以外の条件を固定した中で、最良の検証結果を出す。**\n","\n","### オリジナル課題ルール\n","\n","- 訓練データは`x_train`，テストデータは`x_test`で与えられます．\n","- 下のセルで指定されている`x_train`以外の学習データは使わないでください．\n","\n","### 評価方法\n","\n","- 評価は生成画像の検証データに対するNLL（負の対数尤度）とした。<br>（オリジナル課題は、テストデータに対するNLL）\n","\n","\\begin{equation}\n","-\\sum_{i=1}^Dx_i\\log\\hat{x_i}+(1-x_i)\\log(1-\\hat{x_i})\n","\\end{equation}"]},{"cell_type":"markdown","metadata":{"id":"3Nr2s4ysKyC4"},"source":["### ドライブのマウント"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28744,"status":"ok","timestamp":1690577678284,"user":{"displayName":"Takahiro FUJIWARA DQ4WX0","userId":"15259210674886464118"},"user_tz":-120},"id":"k08zmZ5KK0e4","outputId":"7141f1dd-84d4-4e6e-c5f1-557ec3d47f5e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"Cu4cmQtelx19"},"source":["### データの読み込み（このセルは修正しないでください）"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EsLDDSUJkRx-"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","\n","seed = 1234\n","torch.manual_seed(seed)\n","np.random.seed(seed)\n","\n","# 学習データ\n","x_train = np.load('drive/MyDrive/Colab Notebooks/DLBasics2023_colab/FinalProj/data/x_train.npy')\n","# テストデータ\n","x_test = np.load('drive/MyDrive/Colab Notebooks/DLBasics2023_colab/FinalProj/data/x_test.npy')\n","\n","\n","class dataset(torch.utils.data.Dataset):\n","    def __init__(self, x_test):\n","        self.x_test = x_test.reshape(-1, 784).astype('float32') / 255\n","\n","    def __len__(self):\n","        return self.x_test.shape[0]\n","\n","    def __getitem__(self, idx):\n","        return torch.tensor(self.x_test[idx], dtype=torch.float)\n","\n","trainval_data = dataset(x_train)\n","test_data = dataset(x_test)"]},{"cell_type":"markdown","metadata":{"id":"UrSpHDIWOfK_"},"source":["### VAEの実装\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sKAe0F36nSvU"},"outputs":[],"source":["batch_size = 32\n","\n","val_size = 10000\n","train_size = len(trainval_data) - val_size\n","\n","train_data, val_data = torch.utils.data.random_split(trainval_data, [train_size, val_size])\n","\n","dataloader_train = torch.utils.data.DataLoader(\n","    train_data,\n","    batch_size=batch_size,\n","    shuffle=True\n",")\n","\n","dataloader_valid = torch.utils.data.DataLoader(\n","    val_data,\n","    batch_size=batch_size,\n","    shuffle=True\n",")\n","\n","dataloader_test = torch.utils.data.DataLoader(\n","    test_data,\n","    batch_size=batch_size,\n","    shuffle=False\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PADQiKNa2snb"},"outputs":[],"source":["import torch.nn as nn\n","import torch.optim as optim\n","import torch.autograd as autograd\n","import torch.nn.functional as F\n","from typing import Tuple\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","\n","# torch.log(0)によるnanを防ぐ\n","def torch_log(x):\n","    return torch.log(torch.clamp(x, min=1e-10))\n","\n","# VAEモデルの実装\n","class VAE(nn.Module):\n","    # WRITE ME\n","    def __init__(self, z_dim: int) -> None:\n","        super().__init__()\n","\n","        # Encoder, xを入力にガウス分布のパラメータmu, sigmaを出力\n","        self.dense_enc1 = nn.Linear(28*28, 200)\n","        self.dense_enc2 = nn.Linear(200, 200)\n","        self.dense_encmean = nn.Linear(200, z_dim)\n","        self.dense_encvar = nn.Linear(200, z_dim)\n","\n","        # Decoder, zを入力にベルヌーイ分布のパラメータlambdaを出力\n","        self.dense_dec1 = nn.Linear(z_dim, 200)\n","        self.dense_dec2 = nn.Linear(200, 200)\n","        self.dense_dec3 = nn.Linear(200, 28*28)\n","\n","    def _encoder(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n","        x = F.relu(self.dense_enc1(x))\n","        x = F.relu(self.dense_enc2(x))\n","        mean = self.dense_encmean(x)\n","        std = F.softplus(self.dense_encvar(x))\n","\n","        return mean, std\n","\n","    def _sample_z(self, mean: torch.Tensor, std: torch.Tensor) -> torch.Tensor:\n","        if self.training:\n","            # 再パラメータ化トリック．この乱数は計算グラフで勾配の通り道に無い．\n","            epsilon = torch.randn(mean.shape).to(device)\n","            return mean + std * epsilon\n","        else:\n","            return mean\n","\n","    def _decoder(self, z: torch.Tensor) -> torch.Tensor:\n","        x = F.relu(self.dense_dec1(z))\n","        x = F.relu(self.dense_dec2(x))\n","        # 出力が0~1になるようにsigmoid\n","        x = torch.sigmoid(self.dense_dec3(x))\n","\n","        return x\n","\n","    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n","        mean, std = self._encoder(x)\n","        z = self._sample_z(mean, std)\n","        x = self._decoder(z)\n","        return x, z\n","\n","    def loss(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n","        mean, std = self._encoder(x)\n","\n","        # KL loss(正則化項)の計算. mean, stdは (batch_size , z_dim)\n","        # torch.sumは上式のJ(=z_dim)に関するもの. torch.meanはbatch_sizeに関するものなので,\n","        # 上式には書いてありません.\n","        KL = -0.5 * torch.mean(torch.sum(1 + torch_log(std**2) - mean**2 - std**2, dim=1))\n","\n","        z = self._sample_z(mean, std)\n","        y = self._decoder(z)\n","\n","        # reconstruction loss(負の再構成誤差)の計算. x, yともに (batch_size , 784)\n","        # torch.sumは上式のD(=784)に関するもの. torch.meanはbatch_sizeに関するもの.\n","        reconstruction = torch.mean(torch.sum(x * torch_log(y) + (1 - x) * torch_log(1 - y), dim=1))\n","\n","        return KL, -reconstruction"]},{"cell_type":"markdown","metadata":{"id":"6JhWJqMlM8GQ"},"source":["自分の関数の追加"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0hxzj1M8M-rX"},"outputs":[],"source":["import datetime\n","import pytz\n","import math\n","timezone = 'Europe/Budapest'\n","\n","def datetime_now():\n","    new_timezone = pytz.timezone(timezone)\n","    return datetime.datetime.now().astimezone(new_timezone)\n","\n","class XPrint:\n","    ### 画面と同じものを記録する。\n","    def __init__(self, filename, mystr):\n","        self.filename = filename\n","        if ( mystr != \"\" ):\n","            self.message_time(mystr)\n","    def __call__(self, mystr):\n","        self.message(\"{} {}\".format(datetime_now().strftime(\"%Y/%m/%d %H:%M:%S\"), mystr))\n","    def message(self, mystr):\n","        try:\n","            with open(self.filename, \"a\") as f:\n","                f.write(\"{}\\n\".format(mystr))\n","        except FileNotFoundError:\n","            print(\"* \"+mystr)\n","            return\n","        print(\"  \"+mystr)\n","    def message_time(self, mystr):\n","        self.message(\"{} {}\".format(datetime_now().strftime(\"%Y/%m/%d %H:%M:%S\"), mystr))\n","xprint = XPrint('drive/MyDrive/Colab Notebooks/DLBasics2023_colab/FinalProj/xprint{}.txt'.format(datetime_now().strftime(\"%Y%m%d\")), \"\")\n","\n","class CosineScheduler:\n","    def __init__(self, epochs, lr, warmup_length=5):\n","        \"\"\"\n","        Arguments\n","        ---------\n","        epochs : int\n","            学習のエポック数．\n","        lr : float\n","            学習率．\n","        warmup_length : int\n","            warmupを適用するエポック数．\n","        \"\"\"\n","        self.epochs = epochs\n","        self.lr = lr\n","        self.warmup = warmup_length\n","\n","    def __call__(self, epoch):\n","        \"\"\"\n","        Arguments\n","        ---------\n","        epoch : int\n","            現在のエポック数．\n","        \"\"\"\n","        progress = (epoch - self.warmup) / (self.epochs - self.warmup)\n","        progress = np.clip(progress, 0.0, 1.0)\n","        lr = self.lr * 0.5 * (1. + np.cos(np.pi * progress))\n","\n","        if self.warmup:\n","            lr = lr * min(1., (epoch+1) / self.warmup)\n","        return lr"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1mXUoUJrYyChTzzk6C_xDNjYZ_qFz0Spf"},"id":"nlOZuLu-328i","outputId":"df260f4f-2088-4640-94ba-ef7cd8a6c7f8","executionInfo":{"status":"ok","timestamp":1690581115098,"user_tz":-120,"elapsed":3180504,"user":{"displayName":"Takahiro FUJIWARA DQ4WX0","userId":"15259210674886464118"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["#z_dim = 135 #10\n","z_dim = 10\n","assert z_dim >= 2\n","n_epochs = 400 #15\n","lr=0.001     #0.00151 #0.001\n","scheduler = CosineScheduler(epochs=n_epochs, lr=lr)\n","\n","model = VAE(z_dim).to(device)\n","#optimizer = optim.Adam(model.parameters(), lr=lr) #0.001\n","!pip install japanize_matplotlib >nul\n","import matplotlib.pyplot as plt\n","import japanize_matplotlib\n","plt.clf()\n","gx = []\n","gy = []\n","title_font = {\n","    'color':  'black',\n","    'weight': 'bold',\n","    'size': 12,\n","}\n","\n","min_valid_lower_bound = 9999                                                    # 最小値の初期値\n","for epoch in range(n_epochs):\n","    lr = scheduler(epoch)\n","    optimizer = optim.Adam(model.parameters(), lr=lr) #0.001\n","\n","\n","    losses = []\n","    KL_losses = []\n","    reconstruction_losses = []\n","    model.train()\n","    for x in dataloader_train:\n","\n","        # WRITE ME\n","        x = x.to(device)\n","        model.zero_grad()\n","        # KL_loss, reconstruction_lossの各項の計算\n","        KL_loss, reconstruction_loss = model.loss(x)\n","        # エビデンス下界の最大化のためマイナス付きの各項の値を最小化するようにパラメータを更新\n","        loss = KL_loss + reconstruction_loss\n","        loss.backward()\n","        optimizer.step()\n","\n","        losses.append(loss.cpu().detach().numpy())\n","        KL_losses.append(KL_loss.cpu().detach().numpy())\n","        reconstruction_losses.append(reconstruction_loss.cpu().detach().numpy())\n","\n","    losses_val = []\n","    model.eval()\n","    for x in dataloader_valid:\n","\n","        # WRITE ME\n","        x = x.to(device)\n","        KL_loss, reconstruction_loss = model.loss(x)\n","        loss = KL_loss + reconstruction_loss\n","\n","        losses_val.append(loss.cpu().detach().numpy())\n","    valid_lower_bound = np.average(losses_val)\n","    if valid_lower_bound < min_valid_lower_bound:\n","        min_valid_lower_bound = valid_lower_bound\n","        msg = \"最小値更新\"\n","    else:\n","        msg = \"\"\n","    xprint('EPOCH:%d, Train Lower Bound:%lf, (%lf, %lf), Valid Lower Bound:%lf lr=%.8lf %s' %\n","          (epoch+1, np.average(losses), np.average(KL_losses), np.average(reconstruction_losses), np.average(losses_val), lr, msg))\n","    gx.append(epoch+1)\n","    gy.append(np.average(losses_val))\n","    if (epoch+1) % 10 == 0:\n","        plt.plot(gx, gy, label=f'batch_size={batch_size}, z_dim={z_dim}, lr=cosine annealing')\n","        plt.xlabel(f\"Epoch\")                                     # グラフ表示用\n","        plt.ylabel(f\"NLL (Negative Log-Likelihood)\")                             # グラフ表示用\n","        plt.grid(True)\n","        plt.legend()\n","        plt.title(f\"変分オートエンコーダ（VAE）を用いて\\nFasionMNISTの画像を生成\", fontdict=title_font)\n","        plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yq3scS5j4Rt2"},"outputs":[],"source":["import csv\n","\n","sample_x = []\n","answer = []\n","model.eval()\n","for x in dataloader_test:\n","    x = x.to(device)\n","    y, _ = model(x)\n","    y = y.tolist()\n","    sample_x.extend(y)\n","\n","with open('drive/MyDrive/Colab Notebooks/DLBasics2023_colab/FinalProj/submission_pred.csv', 'w') as file:\n","    writer = csv.writer(file, lineterminator='\\n')\n","    writer.writerows(sample_x)\n","file.close()"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}